---
layout: default
title: Call for Papers
description: Submit your work to COGVL: Cognitive Foundations for Multimodal Models
---

<section class="section">
    <div class="container">
        <div class="section-content">
            <h1 class="section-title">Call for Papers</h1>
            
            <div class="abstract">
                <p>The CogVL workshop provides a forum for students and researchers across computer vision, natural language processing, and cognitive science to explore how cognitively inspired frameworks can enhance the robustness, generalization, and interpretability of VLMs. The workshop will feature invited talks by leading experts and a panel discussion examining how cognitive principles can reshape model architectures, learning paradigms, and evaluation methodologies.</p>
            </div>
            
            <h2>Submission Tracks</h2>
            <p>We welcome submissions covering technical contributions, evaluations, and position papers. Submissions may address topics pertaining to cognitively inspired VLMs, including, but not limited to the topics listed below.</p>
            
            <p>We will have <strong>two tracks</strong> for paper submissions:</p>
            
            <div class="topics-grid" style="margin-top: var(--spacing-md);">
                <div class="topic-card" style="border-left: 4px solid var(--accent-color);">
                    <h3><span class="topic-number">1</span> Track 1: Papers with IEEE/CVF Workshop Proceedings</h3>
                    <p><strong>Page limit:</strong> 8 pages (excluding references)</p>
                    <p><strong>Requirements:</strong></p>
                    <ul style="margin-left: 1.5rem; margin-top: 0.5rem;">
                        <li>Original, previously unpublished papers</li>
                        <li>Dual submissions are <strong>not allowed</strong></li>
                        <li>Accepted papers will be included in the IEEE/CVF workshop proceedings</li>
                    </ul>
                </div>
                
                <div class="topic-card" style="border-left: 4px solid var(--accent-color);">
                    <h3><span class="topic-number">2</span> Track 2: Papers without Workshop Proceedings</h3>
                    <p><strong>Page limit:</strong> â‰¤ 8 pages (excluding references)</p>
                    <p><strong>Requirements:</strong></p>
                    <ul style="margin-left: 1.5rem; margin-top: 0.5rem;">
                        <li>Papers will <strong>not</strong> be included in the proceedings</li>
                        <li>Accepted papers will be publicly shared on the workshop website</li>
                    </ul>
                    <p style="margin-top: 1rem;"><strong>Two subcategories:</strong></p>
                    <ul style="margin-left: 1.5rem; margin-top: 0.5rem;">
                        <li><strong>Novel/ongoing work:</strong> Limited to 4 pages (excluding references)</li>
                        <li><strong>Accepted/previously published papers:</strong> Limited to 8 pages (excluding references)</li>
                    </ul>
                </div>
            </div>
            
            <div class="highlight-box" style="margin-top: var(--spacing-lg);">
                <h3>Submission Site</h3>
                <p>The submission link will be announced soon. Please check back for updates.</p>
            </div>
            
            <h2>Topics of Interest</h2>
            
            <div class="topics-grid">
                <div class="topic-card">
                    <h3><span class="topic-number">1</span> Robustness and Generalization</h3>
                    <p>How can cognitive principles help models overcome spurious correlations and shortcut learning? What evaluation paradigms can reveal whether models have developed robust, generalizable understanding?</p>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);"><strong>Example topics:</strong> Methods for reducing reliance on superficial features through structured priors, benchmarks probing out-of-distribution generalization, training paradigms inspired by developmental psychology or curiosity-driven learning, and interpretability analyses revealing cognitive-like reasoning patterns versus shortcut strategies.</p>
                </div>
                
                <div class="topic-card">
                    <h3><span class="topic-number">2</span> Causal and Counterfactual Reasoning</h3>
                    <p>How can VLMs move beyond surface correlations to understand causal relationships in visual scenes? What role does counterfactual thinking play in robust multimodal reasoning?</p>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);"><strong>Example topics:</strong> Methods for learning causal world models from visual data, architectures supporting counterfactual inference and intervention, benchmarks evaluating causal understanding in image and video, and position papers on the role of causal reasoning.</p>
                </div>
                
                <div class="topic-card">
                    <h3><span class="topic-number">3</span> Compositional and Structured Reasoning</h3>
                    <p>How can models learn to compose visual concepts and reason over structured representations? What cognitive principles can guide the development of compositional generalization in VLMs?</p>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);"><strong>Example topics:</strong> Architectures for compositional visual reasoning, methods for learning object-centric or scene graph representations, benchmarks testing systematic generalization and compositional understanding, and analyses of how compositional biases emerge during training.</p>
                </div>
                
                <div class="topic-card">
                    <h3><span class="topic-number">4</span> Theory of Mind and Social Reasoning</h3>
                    <p>How can VLMs develop an understanding of agents' mental states, goals, and intentions? What is required for genuine social reasoning in multimodal contexts?</p>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);"><strong>Example topics:</strong> Methods for inferring goals and intentions from visual observations, benchmarks evaluating theory of mind in social scenarios, approaches to modeling perspective-taking and false belief understanding, and position papers on the role of social cognition in embodied AI.</p>
                </div>
                
                <div class="topic-card">
                    <h3><span class="topic-number">5</span> Non-Monotonic Reasoning</h3>
                    <p>How can models infer the most likely explanations for observed phenomena? How can they revise their conclusions when presented with new evidence?</p>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);"><strong>Example topics:</strong> Methods for hypothesis generation and explanation, approaches to belief revision and non-monotonic reasoning, benchmarks for evaluating reasoning under uncertainty and surprise, and analyses of how models handle unexpected or anomalous observations.</p>
                </div>
                
                <div class="topic-card">
                    <h3><span class="topic-number">6</span> Dual-process Reasoning and Meta-Cognition</h3>
                    <p>How can we bridge fast, intuitive processing (System 1) with slow, deliberate reasoning (System 2) in VLMs? What role does meta-cognitive monitoring play in reliable reasoning?</p>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);"><strong>Example topics:</strong> Architectures supporting both reflexive and reflective processing, methods for adaptive computation and reasoning, approaches to uncertainty estimation and confidence calibration, computational principles underlying dual-process theories.</p>
                </div>
                
                <div class="topic-card">
                    <h3><span class="topic-number">7</span> Cognition for Embodied and Interactive Agents</h3>
                    <p>How can cognitively inspired approaches improve situational awareness, planning, and collaboration in embodied AI systems? What cognitive capabilities are essential for human-robot interaction?</p>
                    <p style="margin-top: 0.5rem; font-size: 0.9rem; color: var(--text-light);"><strong>Example topics:</strong> Methods for goal inference and intention recognition in interactive settings, approaches to collaborative reasoning and shared mental models, and cognitive architectures for embodied agents.</p>
                </div>
            </div>
            
            <h2>Important Dates</h2>
            <div class="highlight-box">
                <ul class="timeline">
                    <li class="timeline-item">
                        <span class="timeline-date">March 1, 2026</span> - Workshop Paper Submission Deadline
                    </li>
                    <li class="timeline-item">
                        <span class="timeline-date">March 25, 2026</span> - Notification to Authors
                    </li>
                    <li class="timeline-item">
                        <span class="timeline-date">April 5, 2026</span> - Camera Ready Deadline
                    </li>
                </ul>
            </div>
            
            <h2>Review Process</h2>
            <p>All accepted papers will be presented in a poster session to foster discussion and facilitate the exchange of ideas across disciplines. Selected papers will be presented as spotlight talks during the workshop.</p>
            
            <h2>Formatting Requirements</h2>
            <p>Papers should follow the CVPR 2026 formatting guidelines. Page limits vary by track (see Submission Tracks above). All submissions must be in PDF format.</p>
            
            <div class="text-center mt-lg">
                <a href="#" class="btn" style="pointer-events: none; opacity: 0.6;">Submission Site (Coming Soon)</a>
            </div>
        </div>
    </div>
</section>

